\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Week 1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Introduction}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Linear Regression - Model and Cost Function}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Univariate Linear Regression Hypothesis}{1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Cost Function}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}Cost Function Intuition}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Gradient Descent}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Intuition}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Week 2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Multivariate Linear Regression}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Multiple Features}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Gradient Descent for Multiple Variables ($n \geq 1$)}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Feature Scaling}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Learning Rate}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Polynomial Regression}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Computing Parameters Analytically - Normal Equation}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Gradient Descent vs Normal Equation}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Normal Equation Non-invertibility}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Vectorization of Implementation}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Week 3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Classification}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Hypothesis Representation}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Decision Boundary}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Logistic Regression Model}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Cost Function}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Gradient Descent}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Advanced Optimization}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Multi-class Classification (any number of outputs)}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}The Problem of Over-fitting}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Addressing Overfitting}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Regularization}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Regularized Linear Regression}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.4}Regularized Logistic Regression}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Week 4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Neural Networks}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Model Representation}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Applications}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Multiclass Classification}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Week 5}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural Network Cost Function}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.1}Gradient Computation}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.1.2}Intuition on Back Propagation}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Back Propagation in Practice}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Gradient Checking}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Initialization of $\theta $ Parameters}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Putting it all Together}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Week 6}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Evaluating a Learning Algorithm}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Evaluating Hypothesis}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Model Selection - How to Choose the Degree of Polynomial to Fit}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Bias vs. Variance}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Diagnosing Bias vs Variance}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Auto-selecting $\lambda $}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Learning Curves}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.4}Relating to Neural Networks}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Spam Classifier}{17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1}Error Analysis}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Handling Skewed Data}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Precision/recall}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}Trading Off Precision and Recall}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Using Large Data Sets}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Week 7}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Large Margin Classification - Support Vector Machines}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Optimization Objective}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Large Margin Intuition}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Kernels}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.1}Motivation}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.2}Landmarks}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.3}Kernel Function}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.4}How to Choose Landmarks}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.5}SVM with Kernels}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.2.6}SVM Parameters}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Using an SVM}{21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.1}Other Kernels}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.2}Multi-class Classification}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.3}Logistic Regression vs SVM}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.4}Neural Network vs SVM}{23}}
